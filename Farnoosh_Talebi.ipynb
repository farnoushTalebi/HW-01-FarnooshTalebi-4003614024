{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Farnoosh_Talebi.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOcPrv+cUsPWssWVeEI0y+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farnoushTalebi/HW-01-FarnooshTalebi-4003614024/blob/main/Farnoosh_Talebi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3uWZ7imy_Cw",
        "outputId": "6ce9114f-090f-4153-8e8d-ebbdc0670e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Coachinge Zendegi', 'Bavar Konid Ta Bebinid', 'Raaz', 'Gave Banafsh', 'Ertebat Ba Koodak', 'Controle Zehn', 'Khorde Adatha', 'Hooshe Hayajani', 'Miliardere Manavi', 'Az Ranji Ke Mibarim', 'Mega Khalaghyat', 'Shefaye quantomi', 'Asare Morakab', 'Az Dolate Eshgh', 'Tajasome Khalagh', 'Ostade Eshgh', 'Shahnameh', 'Boostan', 'Golestan', 'Nimeye Tarike Vojood', 'Divane Hafez', 'Rayaye Khis', 'Asare Morakab', 'Shahpoor', 'Pari', 'Bamdade Khomar', 'Bavar Konid Ta Bebinid', 'Shenakhte Khoda', 'Ilyad', 'Bachehaye Aseman', 'Asare Parvaneh', 'Karma', 'keleydar', 'Zoorikh', 'Shefaye Moghadas', 'Divane', 'Zarbolmasalha']\n",
            "20th: Nimeye Tarike Vojood\n",
            "Lower to upper case:\n",
            "{('HOOSHE HAYAJANI', 'hooshe hayajani'), ('KHORDE ADATHA', 'khorde adatha'), ('NIMEYE TARIKE VOJOOD', 'nimeye tarike vojood'), ('RAYAYE KHIS', 'rayaye khis'), ('SHENAKHTE KHODA', 'shenakhte khoda'), ('GAVE BANAFSH', 'gave banafsh'), ('BOOSTAN', 'boostan'), ('BACHEHAYE ASEMAN', 'bachehaye aseman'), ('DIVANE HAFEZ', 'divane hafez'), ('MEGA KHALAGHYAT', 'mega khalaghyat'), ('MILIARDERE MANAVI', 'miliardere manavi'), ('SHAHNAMEH', 'shahnameh'), ('SHEFAYE MOGHADAS', 'shefaye moghadas'), ('BAVAR KONID TA BEBINID', 'bavar konid ta bebinid'), ('ERTEBAT BA KOODAK', 'ertebat ba koodak'), ('AZ RANJI KE MIBARIM', 'az ranji ke mibarim'), ('ZARBOLMASALHA', 'zarbolmasalha'), ('GOLESTAN', 'golestan'), ('PARI', 'pari'), ('RAAZ', 'raaz'), ('SHAHPOOR', 'shahpoor'), ('ASARE MORAKAB', 'asare morakab'), ('ASARE PARVANEH', 'asare parvaneh'), ('TAJASOME KHALAGH', 'tajasome khalagh'), ('CONTROLE ZEHN', 'controle zehn'), ('AZ DOLATE ESHGH', 'az dolate eshgh'), ('KARMA', 'karma'), ('KELEYDAR', 'keleydar'), ('ILYAD', 'ilyad'), ('SHEFAYE QUANTOMI', 'shefaye quantomi'), ('OSTADE ESHGH', 'ostade eshgh'), ('COACHINGE ZENDEGI', 'coachinge zendegi'), ('BAMDADE KHOMAR', 'bamdade khomar'), ('ZOORIKH', 'zoorikh'), ('DIVANE', 'divane')}\n",
            "\n",
            "Map-reduce a long text:\n",
            "Apache: 6\n",
            "Spark: 9\n",
            "is: 5\n",
            "an: 3\n",
            "open-source: 1\n",
            "unified: 1\n",
            "analytics: 1\n",
            "engine: 1\n",
            "provides: 1\n",
            "programming: 2\n",
            "clusters: 1\n",
            "implicit: 1\n",
            "fault: 1\n",
            "developed: 2\n",
            "at: 1\n",
            "University: 1\n",
            "of: 13\n",
            "Berkeley's: 1\n",
            "AMPLab,: 1\n",
            "codebase: 1\n",
            "was: 3\n",
            "in: 6\n",
            "read-only: 1\n",
            "multiset: 1\n",
            "items: 1\n",
            "fault-tolerant: 1\n",
            "way.[2]: 1\n",
            "The: 3\n",
            "Dataframe: 1\n",
            "as: 4\n",
            "RDD,: 1\n",
            "1.x,: 1\n",
            "primary: 1\n",
            "(API),: 1\n",
            "but: 1\n",
            "use: 1\n",
            "even: 1\n",
            "though: 1\n",
            "deprecated.[4][5]: 1\n",
            "technology: 1\n",
            "2012: 1\n",
            "response: 1\n",
            "limitations: 1\n",
            "MapReduce: 3\n",
            "forces: 1\n",
            "particular: 1\n",
            "programs: 2\n",
            "read: 1\n",
            "input: 1\n",
            "reduce: 1\n",
            "results: 2\n",
            "map,: 1\n",
            "store: 1\n",
            "Spark's: 1\n",
            "working: 1\n",
            "set: 2\n",
            "offers: 1\n",
            "form: 1\n",
            "memory.[8]: 1\n",
            "managed: 1\n",
            "acyclic: 1\n",
            "graph: 1\n",
            "Nodes: 1\n",
            "operations: 1\n",
            "facilitates: 1\n",
            "both: 1\n",
            "iterative: 2\n",
            "visit: 1\n",
            "multiple: 1\n",
            "loop,: 1\n",
            "database-style: 1\n",
            "querying: 1\n",
            "data.: 1\n",
            "latency: 1\n",
            "may: 1\n",
            "several: 1\n",
            "orders: 1\n",
            "magnitude: 1\n",
            "compared: 1\n",
            "Among: 1\n",
            "class: 1\n",
            "algorithms: 2\n",
            "are: 1\n",
            "training: 1\n",
            "machine: 1\n",
            "learning: 1\n",
            "systems,: 1\n",
            "formed: 1\n",
            "initial: 1\n",
            "impetus: 1\n",
            "developing: 1\n",
            "for: 5\n",
            "large-scale: 1\n",
            "data: 6\n",
            "processing.: 1\n",
            "interface: 2\n",
            "with: 1\n",
            "parallelism: 1\n",
            "and: 4\n",
            "tolerance.: 1\n",
            "Originally: 1\n",
            "the: 23\n",
            "California,: 1\n",
            "later: 1\n",
            "donated: 1\n",
            "to: 3\n",
            "Software: 1\n",
            "Foundation,: 1\n",
            "which: 4\n",
            "has: 2\n",
            "maintained: 2\n",
            "it: 1\n",
            "since.: 1\n",
            "its: 2\n",
            "architectural: 1\n",
            "foundation: 1\n",
            "resilient: 1\n",
            "distributed: 5\n",
            "dataset: 1\n",
            "(RDD),: 1\n",
            "a: 9\n",
            "over: 1\n",
            "cluster: 2\n",
            "machines,: 1\n",
            "that: 2\n",
            "API: 3\n",
            "released: 1\n",
            "abstraction: 1\n",
            "on: 4\n",
            "top: 1\n",
            "followed: 1\n",
            "by: 2\n",
            "Dataset: 3\n",
            "API.: 1\n",
            "In: 1\n",
            "RDD: 3\n",
            "application: 1\n",
            "2.x: 1\n",
            "encouraged[3]: 1\n",
            "not: 1\n",
            "still: 1\n",
            "underlies: 1\n",
            "API.Spark: 1\n",
            "RDDs: 3\n",
            "were: 1\n",
            "computing: 1\n",
            "paradigm,: 1\n",
            "linear: 1\n",
            "dataflow: 1\n",
            "structure: 1\n",
            "programs:: 1\n",
            "from: 1\n",
            "disk,: 1\n",
            "map: 1\n",
            "function: 2\n",
            "across: 1\n",
            "data,: 1\n",
            "reduction: 1\n",
            "disk.: 1\n",
            "(deliberately): 1\n",
            "restricted: 1\n",
            "shared: 1\n",
            "Inside: 1\n",
            "workflow: 1\n",
            "directed: 1\n",
            "(DAG).: 1\n",
            "represent: 2\n",
            "while: 1\n",
            "edges: 1\n",
            "RDDs.: 1\n",
            "implementation: 1\n",
            "algorithms,: 1\n",
            "their: 1\n",
            "times: 1\n",
            "interactive/exploratory: 1\n",
            "analysis,: 1\n",
            "i.e.,: 1\n",
            "repeated: 1\n",
            "such: 1\n",
            "applications: 1\n",
            "be: 1\n",
            "reduced: 1\n",
            "Hadoop: 1\n",
            "implementation.: 1\n"
          ]
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import upper, col \n",
        "from pyspark import SparkContext, SparkConf\n",
        " \n",
        "\n",
        "my_list = ['Coachinge Zendegi',\n",
        "           'Bavar Konid Ta Bebinid',\n",
        "           'Raaz',\n",
        "           'Gave Banafsh',\n",
        "           'Ertebat Ba Koodak',\n",
        "           'Controle Zehn',\n",
        "           'Khorde Adatha',\n",
        "           'Hooshe Hayajani',\n",
        "           'Miliardere Manavi',\n",
        "           'Az Ranji Ke Mibarim',\n",
        "           'Mega Khalaghyat',\n",
        "           'Shefaye quantomi',\n",
        "           'Asare Morakab',\n",
        "           'Az Dolate Eshgh',\n",
        "           'Tajasome Khalagh',\n",
        "           'Ostade Eshgh',\n",
        "           'Shahnameh',\n",
        "           'Boostan',\n",
        "           'Golestan',\n",
        "           'Nimeye Tarike Vojood',\n",
        "           'Divane Hafez',\n",
        "           'Rayaye Khis',\n",
        "           'Asare Morakab',\n",
        "           'Shahpoor',\n",
        "           'Pari',\n",
        "           'Bamdade Khomar',\n",
        "           'Bavar Konid Ta Bebinid',\n",
        "           'Shenakhte Khoda',\n",
        "           'Ilyad',\n",
        "           'Bachehaye Aseman',\n",
        "           'Asare Parvaneh',\n",
        "           'Karma',\n",
        "           'keleydar',\n",
        "           'Zoorikh',\n",
        "           'Shefaye Moghadas',\n",
        "           'Divane',\n",
        "           'Zarbolmasalha']\n",
        "\n",
        "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
        "sparkContext=spark.sparkContext\n",
        "rdd=sparkContext.parallelize(my_list)\n",
        "rddCollect = rdd.collect()\n",
        "print(rddCollect)\n",
        "\n",
        "filtered = rdd.filter(lambda x:x)\n",
        "print(\"20th:\",(filtered.collect())[19])\n",
        "\n",
        "def change_cases(my_list):\n",
        "  return str(my_list).upper(), str(my_list).lower()\n",
        " \n",
        "result = map(change_cases, my_list)\n",
        "print(\"Lower to upper case:\")\n",
        "print(set(result))\n",
        "print()\n",
        "\n",
        "\n",
        "text_file = sparkContext.textFile(\"/content/input.txt\")\n",
        "counts = text_file.flatMap(lambda line: line.split(\" \")).map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y)\n",
        "output = counts.collect()\n",
        "print(\"Map-reduce a long text:\")\n",
        "for (word, count) in output:\n",
        "    print(\"%s: %i\" % (word, count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sCS4ZcNu9mbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LukWEvvL9nrj"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}